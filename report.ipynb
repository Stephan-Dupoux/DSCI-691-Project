{"cells":[{"cell_type":"markdown","metadata":{"id":"zkQDuZm9pIiJ"},"source":["## Project submission header\n","### Submission preparation instructions \n","_Completion of this header is mandatory, subject to point deduction to the scoping assignment._ Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. You must fill out all group member Names and Drexel email addresses in the below markdown list, under header __Project group__. It is required to fill out descriptive notes pertaining to any __External support and stakeholders__, including project mentors (i.e., your advisors) or collaborative relationships in the completion of this submission under the __Additional submission comments__ section at the bottom of the header; please list any supplementary comments pertaining to the submissions in the section labeled __Other__. If no other support was received or parties are involved, leave NA for these sections. \n","\n","For these projects, the target group sizes should be 3&ndash;4 students, but large groups of 5&ndash;6 will be allowed with justification:\n","> if you wish to conduct your project in a large group of more than 4, you must complete the __Large groups justification__ section, which should express why exactly your project will particularly benefit from the larger group, e.g., if you're all working together on a capstone project that you'd like to enrich with NLP+DL. Additionally, large groups are required to submit an additional statement on __Group workload management__, desc\n","\n","_Any distruption of this header's formatting will make your group liable to a possible point deduction._\n","\n","### Project group\n","- Group member 1\n","    - Name: Stephan Dupoux\n","    - Email: sgd45@drexel.edu\n","- Group member 2\n","    - Name: Layla Bouzoubaa\n","    - Email: lb3338@drexel.edu\n","- Group member 3\n","    - Name: Hannah Wurzel\n","    - Email: hjw35@drexel.edu\n","- Group member 4\n","    - Name: Zifeng Wang\n","    - Email: zw438@drexel.edu\n","\n","### Additional submission comments\n","- External support and stakeholders: NA\n","- Other (other): NA\n","- Large groups justification: NA"]},{"cell_type":"markdown","metadata":{"id":"E4roU5IlbvJb"},"source":["# Mining Adverse Drug Events from Tweets"]},{"cell_type":"markdown","metadata":{"id":"KQqR8G2gbvJg"},"source":["## 1. Abstract"]},{"cell_type":"markdown","metadata":{"id":"t2oC-6q0bvJh"},"source":["Adverse drug reactions (ADR) are described as “an appreciably harmful or unpleasant reaction resulting from an intervention related to the use of a medicinal product”<sup>5</sup>. In fact, 3%-7% of hospitalizations occur because of ADR.  Additionally, 10%-20% of hospital patients will endure ADR while hospitalized.  It is thought that nearly 10%-20% of these cases of ADR are severe and can lead to damaging side effects and even death in some cases<sup>6</sup>. In the new age of technology, people are turning to social media to discuss their own ADRs.  These mentions often include slang, misspelled words and emojis making them hard to track down.  In this paper we are aiming to capture these mentions of ADRs.  Specifically, we will be participating in the Social Media Mining for Health 2022 (SMM4H) shared tasks, particularly task 1A, on detecting whether or not a tweet contains mention of an ADR or no mention of an ADR.\n"]},{"cell_type":"markdown","metadata":{"id":"3MIehqNebvJk"},"source":["## 2. Introduction"]},{"cell_type":"markdown","metadata":{"id":"CvOArPDd-YQ-"},"source":["A 2018 paper from Alimova et al. investigated the efficacy of interactive attention networks (IAN) for ADR classification through experimentation of four corpora from askapatient.com, twitter.com, and PubMed2.  The authors believe that deep learning models with attention for sentiment analysis will help with ADR classification.  This study provides an alternative method of addressing the same task as we are. \n","\n","Interactive Attention Method (IAN) was used to address two challenges. The first was to represent the context of the target, ADR and non-ADR. The second was to generate the target representation that can interact with its context. The IAN was composed of word embeddings, obtained using word2vec trained on an unlabeled health corpus of 2.5 million reviews, as input and LSTM layers to get hidden states of words and its context. These components were used to calculate the attention vectors which were then used to detect the important words of the target expression. The attention vectors were used to compute context and target representations that are then concatenated to a single classification vector. Multiple lexicons were used to address a third challenge, to identify the important sentiment words of the target.These methods were experimented against a baseline model, constituted of SVM with Linear kernel.\n","\n","Four corpora were used to conduct experiments.CSIRO Adverse Drug Event Corpus (CADEC), a corpus of annotated user reviews written about Diclofenac or Lipitor on askapatient.com. Annotations for this corpus include 'drug', 'adverse effect', 'disease', 'symptom', 'finding'. MADE is a de-identified electronic health record notes from 21 cancer patients made specifically for an NLP challenge for detecting medication and adverse drug events. The TwiMed annotated corpus consists of sentences extracted from PubMed and tweets. The annotations included the label 'Outcome-negative' that was indicative of an ADR. Lastly, a corpus of tweets from Twitter with the annotations: 'ADR', 'Indication', and 'Other' was included. SentiWordNet, MPQA Subjectivity Lexicon, and Bing Liu's dictionaries were the lexicons used to extract sentiment.\n","\n","All models were evaluated with 5-fold cross-validation and macro-averaged values of recall, precision, and F1 were computed for both classes. The results of this study found that IAN outperformed the baseline model in the macro-averaged measures for both ADR and non-ADR classes, specifically on the Twitter, TwiMed-PubMed, and TwiMed-Twitter corpora.\n","\n","This approach is different from what was proposed by Vydiswaran et al. to address this same classification task at SMM4H 20193. For subtask A, a classifier was developed using SVM with a linear kernel and balanced weights. The model was trained on unigrams from lowercase tweets and individual features weights were found using IDF. A test processing pipeline was developed for subtask B. This pipeline included 5 main steps: removing UTF-8 characters, processing using the Ekphrasis4 tool (spell check, segmentation, tokenization, and word normalization), lemmatization using NLTK, identifying concepts and semantic types using MetaMap, and the identification of  Systematized Nomenclature of Medicine (SNOMED) concepts using cTAKES whose codes were added as additional features. Similar to subtask A, unigram and bigram features were instantiated and weighted by their IDF and SVM with a linear kernel model was developed with balanced classes. \n","\n","For subtask C, four separate models, a biLSTM and a biLSTM-CNN using pre-trained GloVe and word2vec embeddings. The biLSTM with GloVe was selected as the final model due to the best validation accuracy. This model utilized a categorical cross entropy loss function with RMSprop optimizer.The output layer for the classification task was a dense layer followed by the softmax function.\n"]},{"cell_type":"markdown","metadata":{"id":"yHaMtpuGbvJi"},"source":["## 3. Data Cleaning & Pre-processing\n","This first section of your proposal must summarize a relevant research to approximately 2 pages/1000 words in the markdown cell, below. Here, you're required to write a summary written at a level that your classmates will understand. Hence, and new terminology or technical details not covered in the scheduled course topics will need to be covered in detail, but you should avoid spending space on course-covered content. First, list the metadata for the research paper\n","\n","Note: please be critical of the literature you select and reach out to your instructor and/or TAs to ensure it is of high quality. If you select a paper that has not passed through peer review, please understand it may not be fully resolved or evaluated research."]},{"cell_type":"markdown","metadata":{"id":"7c-X1FwIbvJq"},"source":["## 4. Methods\n","The full project description has six sections, covering the following (below). \n","\n"]},{"cell_type":"markdown","metadata":{"id":"f6OzQqZDbvJr"},"source":["#### 4.1 Baseline\n","blah blah logistic\n"]},{"cell_type":"markdown","metadata":{"id":"D1tB-qAZbvJs"},"source":["#### 4.2 Bi-LSTM\n","\n","blah blah"]},{"cell_type":"markdown","metadata":{"id":"EaKok7k5bvJs"},"source":["#### 4.3 Bi-LSTM + RoBERTa\n","blah blah"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Results"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Discussion"]},{"cell_type":"markdown","metadata":{},"source":["## 7. References\n","\n","1. Miftahutdinov, Zulfat, et al. “KFU NLP Team at SMM4H 2019 Tasks: Want to Extract Adverse Drugs Reactions from Tweets? Bert to the Rescue.” Proceedings of the Fourth Social Media Mining for Health Applications (#SMM4H) Workshop & Shared Task, 2019, https://doi.org/10.18653/v1/w19-3207. \n","2. Alimova, I., & Solovyev, V. (2018, October). Interactive attention network for adverse drug reaction classification. In Conference on Artificial Intelligence and Natural Language (pp. 185-196). Springer, Cham.\n","3. Vydiswaran, V. V., Ganzel, G., Romas, B., Yu, D., Austin, A., Bhomia, N., ... & Zimmerman, S. (2019, August). Towards text processing pipelines to identify adverse drug events-related tweets: university of michigan@ SMM4H 2019 task 1. In Proceedings of the fourth social media mining for health applications (# SMM4H) workshop & shared task (pp. 107-109).\n","4. Christos Baziotis, Nikos Pelekis, and Christos Doulkeridis. 2017. DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis. In Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), pages 747–754, Vancouver, Canada. Association for Computational Linguistics.\n","5. Coleman, J. J., & Pontefract, S. K. (2016). Adverse drug reactions. Clinical medicine (London, England), 16(5), 481–485. https://doi.org/10.7861/clinmedicine.16-5-481\n","6. Marsh, D. E. S. (2022, April 18). Adverse drug reactions - clinical pharmacology. Merck Manuals Professional Edition. Retrieved April 29, 2022, from https://www.merckmanuals.com/professional/clinical-pharmacology/adverse-drug-reactions/adverse-drug-reactions  "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"project-1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
