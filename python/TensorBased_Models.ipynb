{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b29a9b",
   "metadata": {},
   "source": [
    "# Mining ADE from English Tweets\n",
    "Task 1a - Classification\n",
    "GOAL: \n",
    "- Create a baseline LSTM and Multi leveled Perceptron \n",
    "- CLASSIFY IF A DRUG EVENT IS PRESENT IN A TWEET with Neural Networks- (ADE/NoADE)\n",
    "\n",
    "## Neural Network Models:\n",
    "- Recursive Neural Network (built in Pytorch by a company called Scoutbee)\n",
    "- Multi Leveled Perceptron\n",
    "- TF-IDF encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25055632",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6863813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import wordpunct_tokenize\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515e3bc",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "### Contains\n",
    "- Importing the data\n",
    "- Text Cleaning (removing emojis)\n",
    "- Stratified shuffling\n",
    "- Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02584130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index: [ 3360  9091  6988 ...   910 12559   444] Test index: [ 5122  1796   298 ...  1025  2309 14625]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweets = pd.read_csv('tweets.tsv', sep='\\t', header=None,\n",
    "                     names=['tweet_id', 'tweet'])\n",
    "classes = pd.read_csv('class.tsv', sep='\\t', header=0)\n",
    "\n",
    "data = pd.merge(tweets, classes, how='left')\n",
    "\n",
    "data = data.replace(r'@\\w+', '', regex=True)\n",
    "\n",
    "# remove any emoji from the tweet\n",
    "data = data.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "data = data.replace(['NoADE', 'ADE'], [0, 1])\n",
    "\n",
    "\n",
    "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=691)\n",
    "X = data['tweet'].to_numpy()\n",
    "y = data['label'].to_numpy()\n",
    "\n",
    "for train_index, test_index in strat_split.split(X, y):\n",
    "    print(f\"Train index: {train_index}\", f\"Test index: {test_index}\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# 4. text representation\n",
    "# convert tweets to matrix of word counts and remove stop words\n",
    "\n",
    "\n",
    "countvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "# normalise count matrix to decrease the effect of word frequencies\n",
    "\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "# vectorize and transform train and test data\n",
    "train_transformed = tfidf.fit_transform(countvec.fit_transform(X_train))\n",
    "test_transformed = tfidf.transform(countvec.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f28504",
   "metadata": {},
   "source": [
    "# Creating a simple Feed Foward Network Model in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a32a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron: with sigmoid activation\n",
      "AUC: 0.6867425757489182\n",
      "Precision: 0.53\n",
      "Recall: 0.40\n",
      "F1 Score: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "activation = 'logistic'\n",
    "nnet = MLPClassifier(solver='adam', random_state=691, max_iter=300, activation = activation)\n",
    "\n",
    "# fit\n",
    "nnet.fit(train_transformed, y_train)\n",
    "y_pred = nnet.predict(test_transformed)\n",
    "\n",
    "# print results\n",
    "print(\"Multilayer Perceptron: with sigmoid activation\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_pred)}\")  #0.6867425757489182\n",
    "print(f\"Precision: {precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=1)[0]:.2f}\") # 0.53\n",
    "print(f\"Recall: {precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=1)[1]:.2f}\") # 0.40\n",
    "print(f\"F1 Score: {precision_recall_fscore_support(y_test, y_pred, average='binary', pos_label=1)[2]:.2f}\") # 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d69cbc",
   "metadata": {},
   "source": [
    "Model did ok in ADE classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c778e",
   "metadata": {},
   "source": [
    "# LSTM model\n",
    "## This pipeline was written by the github user Scoutbee where code comes from.\n",
    "### German Company that created and visualized demos on how to use NLP with packages\n",
    "https://github.com/scoutbee/pytorch-nlp-notebooks\n",
    "https://scoutbee.com/about/\n",
    "\n",
    "https://colab.research.google.com/github/scoutbee/pytorch-nlp-notebooks/blob/master/3_rnn_text_classification.ipynb#scrollTo=dbeeNjQoltCa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63a819",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "Contains:\n",
    "- Removing rare words\n",
    "- Tokenizing the data and adding tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1bfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(tokens, common_tokens, max_len):\n",
    "    return [token if token in common_tokens\n",
    "            else '<UNK>' for token in tokens][-max_len:]\n",
    "\n",
    "\n",
    "def tokenize(text, stop_words):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "class ADE_Cleaner(Dataset):\n",
    "    def __init__(self, data, max_vocab, max_len):\n",
    "        df = data\n",
    "\n",
    "        # Clean and tokenize\n",
    "        print(df.columns)\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "        df['tokens'] = df.tweet.progress_apply(\n",
    "            partial(tokenize, stop_words=stop_words),\n",
    "        )\n",
    "        \n",
    "        # Replace rare words with <UNK>\n",
    "        all_tokens = [sublst for lst in df.tokens.tolist() for sublst in lst]\n",
    "        common_tokens = set(list(zip(\n",
    "            *Counter(all_tokens).most_common(max_vocab)))[0])\n",
    "        df.loc[:, 'tokens'] = df.tokens.progress_apply(\n",
    "            partial(\n",
    "                remove_rare_words,\n",
    "                common_tokens=common_tokens,\n",
    "                max_len=max_len,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Remove sequences with only <UNK>\n",
    "        df = df[df.tokens.progress_apply(\n",
    "            lambda tokens: any(token != '<UNK>' for token in tokens),\n",
    "        )]\n",
    "        \n",
    "        vocab = sorted({\n",
    "            sublst for lst in df.tokens.tolist() for sublst in lst\n",
    "        })\n",
    "        self.token2idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "        \n",
    "        self.token2idx['<PAD>'] = max(self.token2idx.values()) + 1\n",
    "        \n",
    "        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n",
    "        \n",
    "        df['indexed_tokens'] = df.tokens.apply(\n",
    "            lambda tokens: [self.token2idx[token] for token in tokens],\n",
    "        )\n",
    "        self.text = df.tweet.tolist()\n",
    "        self.sequences = df.indexed_tokens.tolist()\n",
    "        self.targets = df.label.tolist()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sequences[i], self.targets[i],  self.text[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a2899b",
   "metadata": {},
   "source": [
    "Split the dataset to train validation and test set and fit the data into a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf37acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"Split dataset into train, validation, and test.\"\"\"\n",
    "    test_length = int(len(corpus) * test_ratio)\n",
    "    valid_length = int(len(corpus) * valid_ratio)\n",
    "    train_length = len(corpus) - valid_length - test_length\n",
    "    return random_split(\n",
    "        corpus, lengths=[train_length, valid_length, test_length],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d1da65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/7dw_676n7xbg0q3jb0ll59400000gn/T/ipykernel_51628/2570516656.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm_notebook().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35101e8b020746e286766aef78a4e31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_id', 'tweet', 'label'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acabff0ba364e80a0455652d2098058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af83791825014cde9809bb3c06ff10eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4ef3abd87f43df879bd09808ea8259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many of the most common vocab words to keep\n",
    "# Uncommon words get replaced with unknown token <UNK>\n",
    "max_vocab = 100000  #@param {type:\"integer\"}\n",
    "\n",
    "# How many tokens long each sequence will be cut to\n",
    "# Shorter sequences will get the padding token <PAD>\n",
    "max_len = 3000  #@param {type:\"slider\", min:16, max:512, step:2}\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "\n",
    "dataset = ADE_Cleaner(data, max_vocab, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "027f97e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16264\n",
      "856\n"
     ]
    }
   ],
   "source": [
    "valid_ratio = 0  \n",
    "test_ratio = 0.05 \n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = Model_split_train_valid_test(\n",
    "    dataset, valid_ratio=valid_ratio, test_ratio=test_ratio)\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)\n",
    "\n",
    "def concatenate(batch):\n",
    "    a = [z[0] for z in batch]\n",
    "    b = torch.LongTensor([item[1] for item in batch])\n",
    "    c = [z[2] for z in batch]\n",
    "    return a, b, c\n",
    "\n",
    "batch_size = 1024 \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=concatenate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=concatenate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=concatenate)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e537b",
   "metadata": {},
   "source": [
    "# Recursive model to predict ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e82aafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, padding_val=0, pad_left=False):\n",
    "    sequence_length = max(len(sequence) for sequence in sequences)\n",
    "    if not pad_left:\n",
    "        return [\n",
    "            sequence + (sequence_length - len(sequence)) * [padding_val]\n",
    "            for sequence in sequences\n",
    "        ]\n",
    "    return [\n",
    "        (sequence_length - len(sequence)) * [padding_val] + sequence\n",
    "        for sequence in sequences\n",
    "    ]\n",
    "\n",
    "\n",
    "class RecursiveNeuralNetworkC(nn.Module):\n",
    "    def __init__(self, output_size, hidden, vocab_size, padding_idx,\n",
    "                 device, dropout=0.3, bidirectional=False, n_layers=1,\n",
    "                 embedding_dimension=50, batch_size=32):\n",
    "        super(RecursiveNeuralNetworkC, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        self.padding_idx = padding_idx\n",
    "        \n",
    "        self.input_size_factor = 2 if bidirectional else 1\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dimension)\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            embedding_dimension,\n",
    "            self.hidden,\n",
    "            self.n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.hidden * self.input_size_factor,\n",
    "            16,\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            16,\n",
    "            self.output_size,\n",
    "        )\n",
    "\n",
    "\n",
    "    def init_hidden(self):\n",
    "        #Two hidden states that are initialized\n",
    "        h0 = torch.randn(\n",
    "            self.n_layers * self.input_size_factor,\n",
    "            self.batch_size,\n",
    "            self.hidden,\n",
    "        )\n",
    "        c0 = torch.randn(\n",
    "            self.n_layers * self.input_size_factor,\n",
    "            self.batch_size,\n",
    "            self.hidden,\n",
    "        )\n",
    "        \n",
    "        h0 = h0.to(self.device)\n",
    "        c0 = c0.to(self.device)\n",
    "\n",
    "        return h0, c0\n",
    "    \n",
    "    def apply_rnn(self, embedding_out, lengths):\n",
    "        packed = pack_padded_sequence(\n",
    "            embedding_out,\n",
    "            lengths,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        activations, _ = self.rnn(packed, self.init_hidden())\n",
    "        activations, _ = pad_packed_sequence(activations, batch_first=True)\n",
    "        \n",
    "        indices = (lengths - 1).view(-1, 1).expand(\n",
    "            activations.size(0), activations.size(2),\n",
    "        ).unsqueeze(1)\n",
    "        indices = indices.to(self.device)\n",
    "        \n",
    "        activations = activations.gather(1, indices).squeeze(1)\n",
    "        return activations\n",
    "\n",
    "    def forward(self, inputs, return_activations=False):\n",
    "        batch_size = len(inputs)\n",
    "    \n",
    "        # This makes the model not break for the last batch that might be less\n",
    "        # than batch_size in size\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "        lengths = torch.LongTensor([len(x) for x in inputs])\n",
    "        lengths, permutation_indices = lengths.sort(0, descending=True)\n",
    "\n",
    "        # Pad sequences so that they are all the same length\n",
    "        padded_inputs = pad_sequences(inputs, padding_val=self.padding_idx)\n",
    "        inputs = torch.LongTensor(padded_inputs)\n",
    "\n",
    "        # Sort inputs\n",
    "        inputs = inputs[permutation_indices].to(self.device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        embedding_out = self.embedding(inputs)\n",
    "        \n",
    "        activations = self.apply_rnn(embedding_out, lengths)\n",
    "\n",
    "        x = F.dropout(torch.relu(self.fc1(activations)), 0.05)\n",
    "        x = self.fc2(x)\n",
    "        out = torch.sigmoid(x)\n",
    "\n",
    "        # Put the output back in correct order\n",
    "        permutation_index_pairs = list(zip(\n",
    "            permutation_indices.tolist(),\n",
    "            list(range(len(permutation_indices))),\n",
    "        ))\n",
    "        reordered_indices = [\n",
    "            pair[1] for pair\n",
    "            in sorted(permutation_index_pairs, key=lambda pair: pair[0])\n",
    "        ]\n",
    "\n",
    "        if return_activations:\n",
    "            return out[reordered_indices], x[reordered_indices]\n",
    "\n",
    "        return out[reordered_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21250f0d",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f735a6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveNeuralNetworkC(\n",
      "  (embedding): Embedding(24411, 256)\n",
      "  (rnn): LSTM(256, 64, num_layers=2, bidirectional=True)\n",
      "  (fc1): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.15  \n",
    "n_rnn_layers = 2  \n",
    "embedding_dimension = 256 \n",
    "hidden_size = 64  \n",
    "is_bidirectional = True \n",
    "max_epochs = 15  \n",
    "learning_rate = 0.001  \n",
    "\n",
    "model = RecursiveNeuralNetworkC(\n",
    "    output_size=2,  \n",
    "    hidden=hidden_size,\n",
    "    embedding_dimension=embedding_dimension,\n",
    "    vocab_size=len(dataset.token2idx),\n",
    "    padding_idx=dataset.token2idx['<PAD>'],\n",
    "    dropout=dropout,\n",
    "    bidirectional=is_bidirectional,\n",
    "    n_layers=n_rnn_layers,\n",
    "    device=device,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9099da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, scheduler, train_loader):\n",
    "    model.train()\n",
    "    total_loss = total = 0\n",
    "    progress_bar = tqdm_notebook(train_loader, desc='Training', leave=False)\n",
    "    for inputs, target, text in progress_bar:\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(inputs)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total += len(target)\n",
    "\n",
    "    return total_loss / total\n",
    "\n",
    "\n",
    "def validate_epoch(model, valid_loader):\n",
    "    model.eval()\n",
    "    total_loss = total = 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm_notebook(valid_loader, desc='Validating', leave=False)\n",
    "        for inputs, target, text in progress_bar:\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total += len(target)\n",
    "\n",
    "    return total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53a74784",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125e744",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3144ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/7dw_676n7xbg0q3jb0ll59400000gn/T/ipykernel_51628/1169750039.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  progress_bar = tqdm_notebook(train_loader, desc='Training', leave=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/7dw_676n7xbg0q3jb0ll59400000gn/T/ipykernel_51628/1169750039.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  progress_bar = tqdm_notebook(valid_loader, desc='Validating', leave=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  1\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  2\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  3\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  4\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  5\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  6\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  7\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  8\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  9\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 10\ttrain_loss: 3.78e-04\tvalid_loss: 4.55e-04\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 11\ttrain_loss: 3.77e-04\tvalid_loss: 4.55e-04\n",
      "\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 0\n",
    "train_losses, valid_losses = [], []\n",
    "for _ in range(max_epochs):\n",
    "    train_loss = train_epoch(model, optimizer, scheduler, train_loader)\n",
    "    valid_loss = validate_epoch(model, test_loader)\n",
    "    \n",
    "    tqdm.write(\n",
    "        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.2e}'\n",
    "        f'\\tvalid_loss: {valid_loss:.2e}\\n',\n",
    "    )\n",
    "    \n",
    "    # Early stopping if the current valid_loss is greater than the last three valid losses\n",
    "    if len(valid_losses) > 2 and all(valid_loss >= loss\n",
    "                                     for loss in valid_losses[-3:]):\n",
    "        print('Stopping early')\n",
    "        break\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    n_epochs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac13b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_ticks = range(1, n_epochs + 1)\n",
    "plt.plot(epoch_ticks, train_losses)\n",
    "plt.plot(epoch_ticks, valid_losses)\n",
    "plt.legend(['Train Loss', 'Test Loss'])\n",
    "plt.title('Losses') \n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epoch_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b847799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dk/7dw_676n7xbg0q3jb0ll59400000gn/T/ipykernel_51628/2438525842.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for inputs, target, text in tqdm_notebook(test_loader, leave=False):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       856\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       856\n",
      "   macro avg       0.50      0.46      0.48       856\n",
      "weighted avg       1.00      0.92      0.96       856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_accuracy = n_examples = 0\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, target, text in tqdm_notebook(test_loader, leave=False):\n",
    "        target = target.to(device)\n",
    "\n",
    "        _, logits = model(inputs, return_activations=True)\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        target = target.cpu().numpy()\n",
    "        \n",
    "        y_true.extend(predictions)\n",
    "        y_pred.extend(target)\n",
    "        \n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14625f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
